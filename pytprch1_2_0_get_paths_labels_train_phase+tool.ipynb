{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytprch1.2.0_get_paths_labels_train_phase+tool.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1axQLq0jb04qQxOAxl26DzU7_FVrP5Wv_",
      "authorship_tag": "ABX9TyO3yHoPXUqUeHk5f/wf+yca",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b66ce11a84d442e9eaea0ddfc629795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_842bc5f7a92c42c9a06b51d2e84f0d76",
              "IPY_MODEL_1433b350440a4233997257ccd857b308",
              "IPY_MODEL_690d383641164ac49fb56727282bc2ad"
            ],
            "layout": "IPY_MODEL_5f93d22f5c9d401cb78c8b6b8aee5130"
          }
        },
        "842bc5f7a92c42c9a06b51d2e84f0d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fc029c3209647dd9c2ad9e4c957efc3",
            "placeholder": "​",
            "style": "IPY_MODEL_2115855375454ff197e1e6ad81debd8e",
            "value": "100%"
          }
        },
        "1433b350440a4233997257ccd857b308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f8e922c974445428e580408b3ff903a",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b354fa8daf64a958940b1e22d743994",
            "value": 102530333
          }
        },
        "690d383641164ac49fb56727282bc2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d63a31613c14f46b06d2df69423ae57",
            "placeholder": "​",
            "style": "IPY_MODEL_10d7941bb01b40fda6edc25b5369261f",
            "value": " 97.8M/97.8M [00:02&lt;00:00, 28.9MB/s]"
          }
        },
        "5f93d22f5c9d401cb78c8b6b8aee5130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc029c3209647dd9c2ad9e4c957efc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2115855375454ff197e1e6ad81debd8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f8e922c974445428e580408b3ff903a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b354fa8daf64a958940b1e22d743994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d63a31613c14f46b06d2df69423ae57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10d7941bb01b40fda6edc25b5369261f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LauraLocke/3D-ResNets-PyTorch/blob/master/pytprch1_2_0_get_paths_labels_train_phase%2Btool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TnHVCfC49Dr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ffcfc78-95bd-4cbe-91f7-051c0b341b16"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code für torch v 1.2.0\n",
        "# get_paths_labels \n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "root_dir = '/content/drive/MyDrive/MA_LL/Datensatz_1143/'\n",
        "img_dir = os.path.join(root_dir, 'data_resize')\n",
        "phase_dir = os.path.join(root_dir, 'Phase_annotations_1143')\n",
        "\n",
        "print(root_dir)\n",
        "print(img_dir)\n",
        "print(phase_dir)\n",
        "\n",
        "\n",
        "def get_dirs(root_dir):\n",
        "    file_paths = []\n",
        "    file_names = []\n",
        "    for lists in os.listdir(root_dir):\n",
        "        path = os.path.join(root_dir, lists)\n",
        "        if os.path.isdir(path):\n",
        "            file_paths.append(path)\n",
        "            file_names.append(os.path.basename(path))\n",
        "    file_names.sort()\n",
        "    file_paths.sort()\n",
        "    return file_names, file_paths\n",
        "\n",
        "def get_files(root_dir):\n",
        "    file_paths = []\n",
        "    file_names = []\n",
        "    for lists in os.listdir(root_dir):\n",
        "        path = os.path.join(root_dir, lists)\n",
        "        if not os.path.isdir(path):\n",
        "            file_paths.append(path)\n",
        "            file_names.append(os.path.basename(path))\n",
        "    file_names.sort()\n",
        "    file_paths.sort()\n",
        "    return file_names, file_paths\n",
        "\n",
        "\n",
        "img_dir_names, img_dir_paths = get_dirs(img_dir)\n",
        "phase_file_names, phase_file_paths = get_files(phase_dir)\n",
        "\n",
        "phase_dict = {}\n",
        "phase_dict_key = ['None', 'Greifen', 'Phase']\n",
        "for i in range(len(phase_dict_key)):\n",
        "    phase_dict[phase_dict_key[i]] = i\n",
        "print(phase_dict)\n",
        "\n",
        "\n",
        "all_info_all = []\n",
        "\n",
        "for j in range(len(phase_file_names)):\n",
        "\n",
        "    phase_file = open(phase_file_paths[j])\n",
        "    phase_count = 0\n",
        "    file_count = 0\n",
        "    frame_num = len(os.listdir(img_dir_paths[j]))\n",
        "    info_all = []\n",
        "    for phase_line in phase_file:\n",
        "        phase_count += 1\n",
        "        if phase_count > 1:\n",
        "            if file_count <= frame_num:\n",
        "                file_count += 1\n",
        "                phase_split = phase_line.split()\n",
        "                info_each = []\n",
        "                img_file_each_path = os.path.join(img_dir_paths[j], img_dir_names[j] + '-' + str(file_count) + '.jpg')\n",
        "                info_each.append(img_file_each_path)\n",
        "                info_each.append(phase_dict[phase_split[1]])\n",
        "                info_all.append(info_each)          \n",
        "\n",
        "    # print(len(info_all))\n",
        "    all_info_all.append(info_all)\n",
        "\n",
        "#for k in range(10):\n",
        "#print(all_info_all[0][k])\n",
        "with open('Greifen.pkl', 'wb') as f:\n",
        "    pickle.dump(all_info_all, f)\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('Greifen.pkl', 'rb') as f:\n",
        "    all_info = pickle.load(f)\n",
        "\n",
        "train_file_paths = []\n",
        "test_file_paths = []\n",
        "val_file_paths = []\n",
        "val_labels = []\n",
        "train_labels = []\n",
        "test_labels = []\n",
        "\n",
        "train_num_each = []\n",
        "val_num_each = []\n",
        "test_num_each = []\n",
        "\n",
        "for i in range(914):\n",
        "    train_num_each.append(len(all_info[i]))\n",
        "    for j in range(len(all_info[i])):\n",
        "        train_file_paths.append(all_info[i][j][0])\n",
        "        train_labels.append(all_info[i][j][1:])\n",
        "\n",
        "print(len(train_file_paths))\n",
        "print(len(train_labels))\n",
        "\n",
        "for i in range(914, 1029):\n",
        "    val_num_each.append(len(all_info[i]))\n",
        "    for j in range(len(all_info[i])):\n",
        "        val_file_paths.append(all_info[i][j][0])\n",
        "        val_labels.append(all_info[i][j][1:])\n",
        "\n",
        "print(len(val_file_paths))\n",
        "print(len(val_labels))\n",
        "\n",
        "for i in range(1029, 1143):\n",
        "    test_num_each.append(len(all_info[i]))\n",
        "    for j in range(len(all_info[i])):\n",
        "        test_file_paths.append(all_info[i][j][0])\n",
        "        test_labels.append(all_info[i][j][1:])\n",
        "\n",
        "print(len(test_file_paths))\n",
        "print(len(test_labels))\n",
        "\n",
        "# for i in range(10):\n",
        "#     print(train_file_paths[i], train_labels[i])\n",
        "#     print(test_file_paths[i], test_labels[i])\n",
        "\n",
        "train_val_test_paths_labels = []\n",
        "train_val_test_paths_labels.append(train_file_paths)\n",
        "train_val_test_paths_labels.append(val_file_paths)\n",
        "train_val_test_paths_labels.append(test_file_paths)\n",
        "\n",
        "train_val_test_paths_labels.append(train_labels)\n",
        "train_val_test_paths_labels.append(val_labels)\n",
        "train_val_test_paths_labels.append(test_labels)\n",
        "\n",
        "train_val_test_paths_labels.append(train_num_each)\n",
        "train_val_test_paths_labels.append(val_num_each)\n",
        "train_val_test_paths_labels.append(test_num_each)\n",
        "\n",
        "with open('/content/drive/MyDrive/MA_LL/Datensatz_1143/train_val_test_paths_labels.pkl', 'wb') as f:\n",
        "    pickle.dump(train_val_test_paths_labels, f)\n",
        "\n",
        "\n",
        "print('Done')\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg8tbQe7Chde",
        "outputId": "9236d0c0-0a17-4bcc-e058-f5ec30c00087"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MA_LL/Datensatz_1143/\n",
            "/content/drive/MyDrive/MA_LL/Datensatz_1143/data_resize\n",
            "/content/drive/MyDrive/MA_LL/Datensatz_1143/Phase_annotations_1143\n",
            "{'None': 0, 'Greifen': 1, 'Phase': 2}\n",
            "104375\n",
            "104375\n",
            "12451\n",
            "12451\n",
            "11369\n",
            "11369\n",
            "Done\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code für torch v 1.2.0\n",
        "# train_phase+tool\n",
        "     \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.init as init\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import DataParallel\n",
        "from torch.utils.data import Sampler\n",
        "from PIL import Image, ImageOps\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "from torchvision.transforms import Lambda\n",
        "import argparse\n",
        "import copy\n",
        "import random\n",
        "import numbers\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn import metrics\n",
        "\n",
        "parser = argparse.ArgumentParser(description='lstm training')\n",
        "parser.add_argument('-g', '--gpu', default=True, type=bool, help='gpu use, default True')\n",
        "parser.add_argument('-s', '--seq', default=10, type=int, help='sequence length, default 10')\n",
        "parser.add_argument('-t', '--train', default=400, type=int, help='train batch size, default 400')\n",
        "parser.add_argument('-v', '--val', default=320, type=int, help='valid batch size, default 10')\n",
        "parser.add_argument('-o', '--opt', default=0, type=int, help='0 for sgd 1 for adam, default 1')\n",
        "parser.add_argument('-m', '--multi', default=1, type=int, help='0 for single opt, 1 for multi opt, default 1')\n",
        "parser.add_argument('-e', '--epo', default=25, type=int, help='epochs to train and val, default 25')\n",
        "parser.add_argument('-w', '--work', default=8, type=int, help='num of workers to use, default 4')\n",
        "parser.add_argument('-f', '--flip', default=1, type=int, help='0 for not flip, 1 for flip, default 0')\n",
        "parser.add_argument('-c', '--crop', default=1, type=int, help='0 rand, 1 cent, 5 five_crop, 10 ten_crop, default 1')\n",
        "parser.add_argument('-l', '--lr', default=5e-5, type=float, help='learning rate for optimizer, default 5e-5')\n",
        "parser.add_argument('--momentum', default=0.9, type=float, help='momentum for sgd, default 0.9')\n",
        "parser.add_argument('--weightdecay', default=5e-4, type=float, help='weight decay for sgd, default 0')\n",
        "parser.add_argument('--dampening', default=0, type=float, help='dampening for sgd, default 0')\n",
        "parser.add_argument('--nesterov', default=False, type=bool, help='nesterov momentum, default False')\n",
        "parser.add_argument('--sgdadjust', default=1, type=int, help='sgd method adjust lr 0 for step 1 for min, default 1')\n",
        "parser.add_argument('--sgdstep', default=5, type=int, help='number of steps to adjust lr for sgd, default 5')\n",
        "parser.add_argument('--sgdgamma', default=0.1, type=float, help='gamma of steps to adjust lr for sgd, default 0.1')\n",
        "\n",
        "\n",
        "### Hinzugefügt um den Code zum Laufen zu kriegen\n",
        "import sys\n",
        "sys.argv=['']\n",
        "del sys\n",
        "###\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "gpu_usg = args.gpu\n",
        "sequence_length = args.seq\n",
        "train_batch_size = args.train\n",
        "val_batch_size = args.val\n",
        "optimizer_choice = args.opt\n",
        "multi_optim = args.multi\n",
        "epochs = args.epo\n",
        "workers = args.work\n",
        "use_flip = args.flip\n",
        "crop_type = args.crop\n",
        "learning_rate = args.lr\n",
        "momentum = args.momentum\n",
        "weight_decay = args.weightdecay\n",
        "dampening = args.dampening\n",
        "use_nesterov = args.nesterov\n",
        "\n",
        "sgd_adjust_lr = args.sgdadjust\n",
        "sgd_step = args.sgdstep\n",
        "sgd_gamma = args.sgdgamma\n",
        "\n",
        "num_gpu = torch.cuda.device_count()\n",
        "use_gpu = (torch.cuda.is_available() and gpu_usg)\n",
        "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
        "\n",
        "print('number of gpu   : {:6d}'.format(num_gpu))\n",
        "print('sequence length : {:6d}'.format(sequence_length))\n",
        "print('train batch size: {:6d}'.format(train_batch_size))\n",
        "print('valid batch size: {:6d}'.format(val_batch_size))\n",
        "print('optimizer choice: {:6d}'.format(optimizer_choice))\n",
        "print('multiple optim  : {:6d}'.format(multi_optim))\n",
        "print('num of epochs   : {:6d}'.format(epochs))\n",
        "print('num of workers  : {:6d}'.format(workers))\n",
        "print('test crop type  : {:6d}'.format(crop_type))\n",
        "print('whether to flip : {:6d}'.format(use_flip))\n",
        "print('learning rate   : {:.4f}'.format(learning_rate))\n",
        "print('momentum for sgd: {:.4f}'.format(momentum))\n",
        "print('weight decay    : {:.4f}'.format(weight_decay))\n",
        "print('dampening       : {:.4f}'.format(dampening))\n",
        "print('use nesterov    : {:6d}'.format(use_nesterov))\n",
        "print('method for sgd  : {:6d}'.format(sgd_adjust_lr))\n",
        "print('step for sgd    : {:6d}'.format(sgd_step))\n",
        "print('gamma for sgd   : {:.4f}'.format(sgd_gamma))\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        with Image.open(f) as img:\n",
        "            return img.convert('RGB')\n",
        "\n",
        "class RandomCrop(object):\n",
        "\n",
        "    def __init__(self, size, padding=0):\n",
        "        if isinstance(size, numbers.Number):\n",
        "            self.size = (int(size), int(size))\n",
        "        else:\n",
        "            self.size = size\n",
        "        self.padding = padding\n",
        "        self.count = 0\n",
        "\n",
        "    def __call__(self, img):\n",
        "\n",
        "        if self.padding > 0:\n",
        "            img = ImageOps.expand(img, border=self.padding, fill=0)\n",
        "\n",
        "        w, h = img.size\n",
        "        th, tw = self.size\n",
        "        if w == tw and h == th:\n",
        "            return img\n",
        "\n",
        "        random.seed(self.count // sequence_length)\n",
        "        x1 = random.randint(0, w - tw)\n",
        "        y1 = random.randint(0, h - th)\n",
        "        # print(self.count, x1, y1)\n",
        "        self.count += 1\n",
        "        return img.crop((x1, y1, x1 + tw, y1 + th))\n",
        "\n",
        "\n",
        "class RandomHorizontalFlip(object):\n",
        "    def __init__(self):\n",
        "        self.count = 0\n",
        "\n",
        "    def __call__(self, img):\n",
        "        seed = self.count // sequence_length\n",
        "        random.seed(seed)\n",
        "        prob = random.random()\n",
        "        self.count += 1\n",
        "        # print(self.count, seed, prob)\n",
        "        if prob < 0.5:\n",
        "            return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        return img\n",
        "\n",
        "class RandomRotation(object):\n",
        "    def __init__(self,degrees):\n",
        "        self.degrees = degrees\n",
        "        self.count = 0\n",
        "\n",
        "    def __call__(self, img):\n",
        "        seed = self.count // sequence_length\n",
        "        random.seed(seed)\n",
        "        self.count += 1\n",
        "        angle = random.randint(-self.degrees,self.degrees)\n",
        "        return TF.rotate(img, angle)\n",
        "\n",
        "class ColorJitter(object):\n",
        "    def __init__(self,brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1):\n",
        "        self.brightness = brightness\n",
        "        self.contrast = contrast\n",
        "        self.saturation = saturation\n",
        "        self.hue = hue\n",
        "        self.count = 0\n",
        "\n",
        "    def __call__(self, img):\n",
        "        seed = self.count // sequence_length\n",
        "        random.seed(seed)\n",
        "        self.count += 1\n",
        "        brightness_factor = random.uniform(1 - self.brightness, 1 + self.brightness)\n",
        "        contrast_factor = random.uniform(1 - self.contrast, 1 + self.contrast)\n",
        "        saturation_factor = random.uniform(1 - self.saturation, 1 + self.saturation)\n",
        "        hue_factor = random.uniform(- self.hue, self.hue)\n",
        "\n",
        "        img_ = TF.adjust_brightness(img,brightness_factor)\n",
        "        img_ = TF.adjust_contrast(img_,contrast_factor)\n",
        "        img_ = TF.adjust_saturation(img_,saturation_factor)\n",
        "        img_ = TF.adjust_hue(img_,hue_factor)\n",
        "        \n",
        "        return img_\n",
        "\n",
        "\n",
        "class GreifenDataset(Dataset):\n",
        "    def __init__(self, file_paths, file_labels, transform=None,\n",
        "                 loader=pil_loader):\n",
        "        self.file_paths = file_paths\n",
        "        self.file_labels_phase = file_labels[:] #[:,0]\n",
        "        self.file_labels_tool = file_labels[:] # [:,range(1,8)]\n",
        "        self.transform = transform\n",
        "        self.loader = loader\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_names = self.file_paths[index]\n",
        "        labels_phase = self.file_labels_phase[index]\n",
        "        labels_tool = self.file_labels_tool[index]\n",
        "        imgs = self.loader(img_names)\n",
        "        if self.transform is not None:\n",
        "            imgs = self.transform(imgs)\n",
        "\n",
        "        return imgs, labels_phase, labels_tool\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "\n",
        "class resnet_lstm(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(resnet_lstm, self).__init__()\n",
        "        resnet = models.resnet50(pretrained=True)\n",
        "        self.share = torch.nn.Sequential()\n",
        "        self.share.add_module(\"conv1\", resnet.conv1)\n",
        "        self.share.add_module(\"bn1\", resnet.bn1)\n",
        "        self.share.add_module(\"relu\", resnet.relu)\n",
        "        self.share.add_module(\"maxpool\", resnet.maxpool)\n",
        "        self.share.add_module(\"layer1\", resnet.layer1)\n",
        "        self.share.add_module(\"layer2\", resnet.layer2)\n",
        "        self.share.add_module(\"layer3\", resnet.layer3)\n",
        "        self.share.add_module(\"layer4\", resnet.layer4)\n",
        "        self.share.add_module(\"avgpool\", resnet.avgpool)\n",
        "        self.lstm = nn.LSTM(2048, 512, batch_first=True)\n",
        "        self.fc = nn.Linear(512, 7)\n",
        "        self.fc_h = nn.Linear(512, 512)\n",
        "        self.fc2 = nn.Linear(2048, 7)\n",
        "\n",
        "        init.xavier_normal_(self.lstm.all_weights[0][0])\n",
        "        init.xavier_normal_(self.lstm.all_weights[0][1])\n",
        "        init.xavier_uniform_(self.fc.weight)\n",
        "        init.xavier_uniform_(self.fc2.weight)\n",
        "        init.xavier_uniform_(self.fc_h.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3, 224, 224)\n",
        "        x = self.share.forward(x)\n",
        "        x = x.view(-1, 2048)\n",
        "        z = self.fc2(x)\n",
        "        x = x.view(-1, sequence_length, 2048)\n",
        "        self.lstm.flatten_parameters()\n",
        "        y, _ = self.lstm(x)\n",
        "        y = y.contiguous().view(-1, 512)\n",
        "        y = F.relu(self.fc_h(y))\n",
        "        y = self.fc(y)\n",
        "        return y, z\n",
        "\n",
        "\n",
        "def get_useful_start_idx(sequence_length, list_each_length):\n",
        "    count = 1\n",
        "    idx = []\n",
        "    for i in range(len(list_each_length)):\n",
        "        for j in range(count, count + (list_each_length[i] + 1 - sequence_length)):\n",
        "            idx.append(j)\n",
        "        count += list_each_length[i]\n",
        "    return idx\n",
        "\n",
        "\n",
        "def get_data(data_path):\n",
        "    with open(data_path, 'rb') as f:\n",
        "        train_test_paths_labels = pickle.load(f)\n",
        "    train_paths = train_test_paths_labels[0]\n",
        "    val_paths = train_test_paths_labels[1]\n",
        "    train_labels = train_test_paths_labels[3]\n",
        "    val_labels = train_test_paths_labels[4]\n",
        "    train_num_each = train_test_paths_labels[6]\n",
        "    val_num_each = train_test_paths_labels[7]\n",
        "\n",
        "    print('train_paths  : {:6d}'.format(len(train_paths)))\n",
        "    print('train_labels : {:6d}'.format(len(train_labels)))\n",
        "    print('valid_paths  : {:6d}'.format(len(val_paths)))\n",
        "    print('valid_labels : {:6d}'.format(len(val_labels)))\n",
        "\n",
        "    train_labels = np.asarray(train_labels, dtype=object) #dtype=np.int64\n",
        "    val_labels = np.asarray(val_labels, dtype=object) #dtype=np.int64\n",
        "\n",
        "    train_transforms = None\n",
        "    test_transforms = None\n",
        "\n",
        "    if use_flip == 0:\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.Resize((250, 250)),\n",
        "            transforms.RandomCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.44893518,0.3226702,0.34424525],[0.22357443,0.18503027,0.1900281])\n",
        "        ])\n",
        "    elif use_flip == 1:\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.Resize((250, 250)),\n",
        "            RandomCrop(224),\n",
        "            ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
        "            RandomHorizontalFlip(),\n",
        "            RandomRotation(5),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.44893518,0.3226702,0.34424525],[0.22357443,0.18503027,0.1900281])\n",
        "        ])\n",
        "\n",
        "    if crop_type == 0:\n",
        "        test_transforms = transforms.Compose([\n",
        "            transforms.Resize((250, 250)),\n",
        "            transforms.RandomCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.44893518,0.3226702,0.34424525],[0.22357443,0.18503027,0.1900281])\n",
        "        ])\n",
        "    elif crop_type == 1:\n",
        "        test_transforms = transforms.Compose([\n",
        "            transforms.Resize((250, 250)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.44893518,0.3226702,0.34424525],[0.22357443,0.18503027,0.1900281])\n",
        "        ])\n",
        "    elif crop_type == 2:\n",
        "        test_transforms = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.44893518,0.3226702,0.34424525],[0.22357443,0.18503027,0.1900281])\n",
        "        ])\n",
        "    elif crop_type == 5:\n",
        "        test_transforms = transforms.Compose([\n",
        "            transforms.Resize((250, 250)),\n",
        "            transforms.FiveCrop(224),\n",
        "            Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "            Lambda(\n",
        "                lambda crops: torch.stack(\n",
        "                    [transforms.Normalize([0.44893518,0.3226702,0.34424525],[0.22357443,0.18503027,0.1900281])(crop) for crop in crops]))\n",
        "        ])\n",
        "    elif crop_type == 10:\n",
        "        test_transforms = transforms.Compose([\n",
        "            transforms.Resize((250, 250)),\n",
        "            transforms.TenCrop(224),\n",
        "            Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "            Lambda(\n",
        "                lambda crops: torch.stack(\n",
        "                    [transforms.Normalize([0.44893518,0.3226702,0.34424525],[0.22357443,0.18503027,0.1900281])(crop) for crop in crops]))\n",
        "        ])\n",
        "\n",
        "    train_dataset = GreifenDataset(train_paths, train_labels, train_transforms)\n",
        "    val_dataset = GreifenDataset(val_paths, val_labels, test_transforms)\n",
        "#    test_dataset = GreifenDataset(test_paths, test_labels, test_transforms)\n",
        "\n",
        "    return train_dataset, train_num_each, val_dataset, val_num_each\n",
        "\n",
        "\n",
        "# 序列采样sampler\n",
        "class SeqSampler(Sampler):\n",
        "    def __init__(self, data_source, idx):\n",
        "        super().__init__(data_source)\n",
        "        self.data_source = data_source\n",
        "        self.idx = idx\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx)\n",
        "\n",
        "\n",
        "sig_f = nn.Sigmoid()\n",
        "\n",
        "\n",
        "def valMinibatch(testloader,model):\n",
        "    model.eval()\n",
        "    criterion_tool = nn.BCEWithLogitsLoss(size_average=False)\n",
        "    criterion_phase = nn.CrossEntropyLoss(size_average=False)\n",
        "    with torch.no_grad():\n",
        "        val_loss_tool = 0.0\n",
        "        val_corrects_tool = 0.0\n",
        "        val_loss_phase = 0.0\n",
        "        val_corrects_phase = 0.0\n",
        "        for data in testloader:\n",
        "            if use_gpu:\n",
        "                inputs, labels_phase, labels_tool = data[0].to(device), data[1].to(device), data[2].to(device)\n",
        "            else:\n",
        "                inputs, labels_phase, labels_tool = data[0], data[1], data[2]\n",
        "\n",
        "            labels_phase = labels_phase[(sequence_length - 1)::sequence_length]\n",
        "\n",
        "            inputs = inputs.view(-1, sequence_length, 3, 224, 224)\n",
        "            outputs_phase, outputs_tool = model.forward(inputs)\n",
        "            outputs_phase = outputs_phase[sequence_length - 1::sequence_length]\n",
        "\n",
        "            _, preds_phase = torch.max(outputs_phase.data, 1)\n",
        "            loss_phase = criterion_phase(outputs_phase, labels_phase)\n",
        "\n",
        "            sig_out = sig_f(outputs_tool.data)\n",
        "            preds_tool = (sig_out.cpu() > 0.5).mul_(1)\n",
        "            preds_tool = preds_tool.float()\n",
        "\n",
        "            labels_tool = labels_tool.data.float()\n",
        "            loss_tool = criterion_tool(outputs_tool, labels_tool)\n",
        "\n",
        "            val_loss_tool += loss_tool.data.item()\n",
        "            val_loss_phase += loss_phase.data.item()\n",
        "\n",
        "            val_corrects_tool += torch.sum(preds_tool == labels_tool.data.cpu())\n",
        "            val_corrects_phase += torch.sum(preds_phase == labels_phase.data)\n",
        "\n",
        "    model.train()\n",
        "    return (val_loss_phase, val_loss_tool), (val_corrects_phase, val_corrects_tool)\n",
        "\n",
        "\n",
        "def train_model(train_dataset, train_num_each, val_dataset, val_num_each):\n",
        "    # TensorBoard\n",
        "    writer = SummaryWriter('runs/log_tool+phase')\n",
        "\n",
        "    num_train = len(train_dataset)\n",
        "    num_val = len(val_dataset)\n",
        "\n",
        "    train_useful_start_idx = get_useful_start_idx(sequence_length, train_num_each)\n",
        "    val_useful_start_idx = get_useful_start_idx(sequence_length, val_num_each)\n",
        "\n",
        "    num_train_we_use = len(train_useful_start_idx)\n",
        "    num_val_we_use = len(val_useful_start_idx)\n",
        "    # num_train_we_use = len(train_useful_start_idx) // num_gpu * num_gpu\n",
        "    # num_val_we_use = len(val_useful_start_idx) // num_gpu * num_gpu\n",
        "    # num_train_we_use = 8000\n",
        "    # num_val_we_use = 800\n",
        "\n",
        "    train_we_use_start_idx = train_useful_start_idx[0:num_train_we_use]\n",
        "    val_we_use_start_idx = val_useful_start_idx[0:num_val_we_use]\n",
        "\n",
        "    #    np.random.seed(0)\n",
        "    # np.random.shuffle(train_we_use_start_idx)\n",
        "    train_idx = []\n",
        "    for i in range(num_train_we_use):\n",
        "        for j in range(sequence_length):\n",
        "            train_idx.append(train_we_use_start_idx[i] + j)\n",
        "\n",
        "    val_idx = []\n",
        "    for i in range(num_val_we_use):\n",
        "        for j in range(sequence_length):\n",
        "            val_idx.append(val_we_use_start_idx[i] + j)\n",
        "\n",
        "    num_train_all = len(train_idx)\n",
        "    num_val_all = len(val_idx)\n",
        "\n",
        "    print('num of train dataset: {:6d}'.format(num_train))\n",
        "    print('num train start idx : {:6d}'.format(len(train_useful_start_idx)))\n",
        "    print('last idx train start: {:6d}'.format(train_useful_start_idx[-1]))\n",
        "    print('num of train we use : {:6d}'.format(num_train_we_use))\n",
        "    print('num of all train use: {:6d}'.format(num_train_all))\n",
        "    print('num of valid dataset: {:6d}'.format(num_val))\n",
        "    print('num valid start idx : {:6d}'.format(len(val_useful_start_idx)))\n",
        "    print('last idx valid start: {:6d}'.format(val_useful_start_idx[-1]))\n",
        "    print('num of valid we use : {:6d}'.format(num_val_we_use))\n",
        "    print('num of all valid use: {:6d}'.format(num_val_all))\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=val_batch_size,\n",
        "        sampler=SeqSampler(val_dataset, val_idx),\n",
        "        num_workers=workers,\n",
        "        pin_memory=False\n",
        "    )\n",
        "\n",
        "    #____ hinzugefügt, gibt Infos zum model aus \n",
        "    #model = resnet_lstm()\n",
        "    #optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    # Print model's state_dict\n",
        "    #print(\"Model's state_dict:\")\n",
        "    #for param_tensor in model.state_dict():\n",
        "    #   print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "    # Print optimizer's state_dict\n",
        "    #print(\"Optimizer's state_dict:\")\n",
        "    #for var_name in optimizer.state_dict():\n",
        "    #    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
        "    #_____\n",
        "\n",
        "    model = resnet_lstm()\n",
        "    model.load_state_dict(torch.load(\"./best_model_phase/lstm_epoch_10_length_10_opt_0_mulopt_1_flip_1_crop_1_batch_400_train_9940_val_7786.pth\"),strict=False)\n",
        "    model.load_state_dict(torch.load(\"./temp/lr5e-5/latest_model_tool_3.pth\"),strict=False)\n",
        "    if use_gpu:\n",
        "        model = DataParallel(model)\n",
        "        model.to(device)\n",
        "\n",
        "    criterion_tool = nn.BCEWithLogitsLoss(size_average=False)\n",
        "    criterion_phase = nn.CrossEntropyLoss(size_average=False)\n",
        "\n",
        "    optimizer = None\n",
        "    exp_lr_scheduler = None\n",
        "\n",
        "    if multi_optim == 0:\n",
        "        if optimizer_choice == 0:\n",
        "            optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, dampening=dampening,\n",
        "                                  weight_decay=weight_decay, nesterov=use_nesterov)\n",
        "            if sgd_adjust_lr == 0:\n",
        "                exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=sgd_adjust_lr, gamma=sgd_gamma)\n",
        "            elif sgd_adjust_lr == 1:\n",
        "                exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
        "        elif optimizer_choice == 1:\n",
        "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    elif multi_optim == 1:\n",
        "        if optimizer_choice == 0:\n",
        "            optimizer = optim.SGD([\n",
        "                {'params': model.module.share.parameters()},\n",
        "                {'params': model.module.lstm.parameters(), 'lr': learning_rate},\n",
        "                {'params': model.module.fc.parameters(), 'lr': learning_rate},\n",
        "                {'params': model.module.fc_h.parameters(), 'lr': learning_rate},\n",
        "                {'params': model.module.fc2.parameters(), 'lr': learning_rate},\n",
        "            ], lr=learning_rate / 10, momentum=momentum, dampening=dampening,\n",
        "                weight_decay=weight_decay, nesterov=use_nesterov)\n",
        "            if sgd_adjust_lr == 0:\n",
        "                exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=sgd_adjust_lr, gamma=sgd_gamma)\n",
        "            elif sgd_adjust_lr == 1:\n",
        "                exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
        "        elif optimizer_choice == 1:\n",
        "            optimizer = optim.Adam([\n",
        "                {'params': model.module.share.parameters()},\n",
        "                {'params': model.module.lstm.parameters(), 'lr': learning_rate},\n",
        "                {'params': model.module.fc.parameters(), 'lr': learning_rate},\n",
        "                {'params': model.module.fc_h.parameters(), 'lr': learning_rate},\n",
        "                {'params': model.module.fc2.parameters(), 'lr': learning_rate},\n",
        "            ], lr=learning_rate / 10)\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "    best_val_accuracy_tool = 0.0\n",
        "    correspond_train_acc_tool = 0.0\n",
        "    best_val_accuracy_phase = 0.0\n",
        "    correspond_train_acc_phase = 0.0\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # np.random.seed(epoch)\n",
        "        np.random.shuffle(train_we_use_start_idx)\n",
        "        train_idx = []\n",
        "        for i in range(num_train_we_use):\n",
        "            for j in range(sequence_length):\n",
        "                train_idx.append(train_we_use_start_idx[i] + j)\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=train_batch_size,\n",
        "            sampler=SeqSampler(train_dataset, train_idx),\n",
        "            num_workers=workers,\n",
        "            pin_memory=False\n",
        "        )\n",
        "\n",
        "        # Sets the module in training mode.\n",
        "        model.train()\n",
        "        train_loss_tool = 0.0\n",
        "        train_corrects_tool = 0\n",
        "        train_loss_phase = 0.0\n",
        "        train_corrects_phase = 0\n",
        "        batch_progress = 0.0\n",
        "        running_loss_tool = 0.0\n",
        "        minibatch_correct_tool = 0.0\n",
        "        running_loss_phase = 0.0\n",
        "        minibatch_correct_phase = 0.0\n",
        "        train_start_time = time.time()\n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            if use_gpu:\n",
        "                inputs, labels_phase, labels_tool = data[0].to(device), data[1].to(device),data[2].to(device)\n",
        "            else:\n",
        "                inputs, labels_phase, labels_tool = data[0], data[1], data[2]\n",
        "\n",
        "            labels_phase = labels_phase[(sequence_length - 1)::sequence_length]\n",
        "\n",
        "            inputs = inputs.view(-1, sequence_length, 3, 224, 224)\n",
        "            outputs_phase, outputs_tool = model.forward(inputs)\n",
        "            outputs_phase = outputs_phase[sequence_length - 1::sequence_length]\n",
        "\n",
        "            _, preds_phase = torch.max(outputs_phase.data, 1)\n",
        "            loss_phase = criterion_phase(outputs_phase, labels_phase)\n",
        "\n",
        "            sig_out = sig_f(outputs_tool.data)\n",
        "            preds_tool = (sig_out.cpu() > 0.5).mul_(1)\n",
        "            preds_tool = preds_tool.float()\n",
        "\n",
        "            labels_tool = labels_tool.data.float()\n",
        "            loss_tool = criterion_tool(outputs_tool, labels_tool)\n",
        "\n",
        "            loss = loss_tool + loss_phase\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss_tool += loss_tool.data.item()\n",
        "            train_loss_tool += loss_tool.data.item()\n",
        "            running_loss_phase += loss_phase.data.item()\n",
        "            train_loss_phase += loss_phase.data.item()\n",
        "\n",
        "            batch_corrects_tool = torch.sum(preds_tool == labels_tool.data.cpu())\n",
        "            train_corrects_tool += batch_corrects_tool\n",
        "            minibatch_correct_tool += batch_corrects_tool\n",
        "\n",
        "            batch_corrects_phase = torch.sum(preds_phase == labels_phase.data)\n",
        "            train_corrects_phase += batch_corrects_phase\n",
        "            minibatch_correct_phase += batch_corrects_phase\n",
        "\n",
        "\n",
        "            if i % 500 == 499:\n",
        "                # ...log the running loss\n",
        "                batch_iters = epoch * num_train_all/sequence_length + i*train_batch_size/sequence_length\n",
        "                writer.add_scalar('training loss tool',\n",
        "                                  running_loss_tool / (train_batch_size*500) / 7,\n",
        "                                  batch_iters)\n",
        "                # ...log the training acc\n",
        "                writer.add_scalar('training acc tool',\n",
        "                                  float(minibatch_correct_tool) / (float(train_batch_size)*500) / 7,\n",
        "                                  batch_iters)\n",
        "                writer.add_scalar('training loss phase',\n",
        "                                  running_loss_phase / (train_batch_size*500/sequence_length) ,\n",
        "                                  batch_iters)\n",
        "                # ...log the training acc\n",
        "                writer.add_scalar('training acc phase',\n",
        "                                  float(minibatch_correct_phase) / (float(train_batch_size)*500/sequence_length),\n",
        "                                  batch_iters)\n",
        "                # ...log the val acc loss\n",
        "\n",
        "                (val_loss_phase, val_loss_tool), (val_corrects_phase, val_corrects_tool) = valMinibatch(val_loader, model)\n",
        "                writer.add_scalar('validation acc miniBatch tool',\n",
        "                                  float(val_corrects_tool) / float(num_val_all) / 7,\n",
        "                                  batch_iters)\n",
        "                writer.add_scalar('validation loss miniBatch tool',\n",
        "                                  float(val_loss_tool) / float(num_val_all) / 7,\n",
        "                                  batch_iters)\n",
        "                writer.add_scalar('validation acc miniBatch phase',\n",
        "                                  float(val_corrects_phase) / float(num_val_we_use),\n",
        "                                  batch_iters)\n",
        "                writer.add_scalar('validation loss miniBatch phase',\n",
        "                                  float(val_loss_phase) / float(num_val_we_use),\n",
        "                                  batch_iters)\n",
        "\n",
        "                running_loss_tool = 0.0\n",
        "                minibatch_correct_tool = 0.0\n",
        "                running_loss_phase = 0.0\n",
        "                minibatch_correct_phase = 0.0\n",
        "\n",
        "            if (i+1)*train_batch_size >= num_train_all:               \n",
        "                running_loss_tool = 0.0\n",
        "                minibatch_correct_tool = 0.0\n",
        "                running_loss_phase = 0.0\n",
        "                minibatch_correct_phase = 0.0\n",
        "\n",
        "            batch_progress += 1\n",
        "            if batch_progress*train_batch_size >= num_train_all:\n",
        "                percent = 100.0\n",
        "                print('Batch progress: %s [%d/%d]' % (str(percent) + '%', num_train_all, num_train_all), end='\\n')\n",
        "            else:\n",
        "                percent = round(batch_progress*train_batch_size / num_train_all * 100, 2)\n",
        "                print('Batch progress: %s [%d/%d]' % (str(percent) + '%', batch_progress*train_batch_size, num_train_all), end='\\r')\n",
        "\n",
        "        train_elapsed_time = time.time() - train_start_time\n",
        "        train_accuracy_tool = float(train_corrects_tool) / float(num_train_all) / 7\n",
        "        train_average_loss_tool = train_loss_tool / num_train_all / 7\n",
        "        train_accuracy_phase = float(train_corrects_phase) / float(num_train_all) * sequence_length\n",
        "        train_average_loss_phase = train_loss_phase / num_train_all * sequence_length\n",
        "\n",
        "        # Sets the module in evaluation mode.\n",
        "        model.eval()\n",
        "        val_loss_tool = 0.0\n",
        "        val_corrects_tool = 0\n",
        "        val_loss_phase = 0.0\n",
        "        val_corrects_phase = 0\n",
        "        val_start_time = time.time()\n",
        "        val_progress = 0\n",
        "        val_all_preds_tool = []\n",
        "        val_all_labels_tool = []\n",
        "        val_all_preds_phase = []\n",
        "        val_all_labels_phase = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in val_loader:\n",
        "                if use_gpu:\n",
        "                    inputs, labels_phase, labels_tool = data[0].to(device), data[1].to(device),data[2].to(device)\n",
        "                else:\n",
        "                    inputs, labels_phase, labels_tool = data[0], data[1], data[2]\n",
        "\n",
        "                labels_phase = labels_phase[(sequence_length - 1)::sequence_length]\n",
        "\n",
        "                inputs = inputs.view(-1, sequence_length, 3, 224, 224)\n",
        "                outputs_phase, outputs_tool = model.forward(inputs)\n",
        "                outputs_phase = outputs_phase[sequence_length - 1::sequence_length]\n",
        "\n",
        "                _, preds_phase = torch.max(outputs_phase.data, 1)\n",
        "                loss_phase = criterion_phase(outputs_phase, labels_phase)\n",
        "\n",
        "                sig_out = sig_f(outputs_tool.data)\n",
        "                preds_tool = (sig_out.cpu() > 0.5).mul_(1)\n",
        "                preds_tool = preds_tool.float()\n",
        "\n",
        "                labels_tool = labels_tool.data.float()\n",
        "                loss_tool = criterion_tool(outputs_tool, labels_tool)\n",
        "\n",
        "                val_loss_tool += loss_tool.data.item()\n",
        "                val_loss_phase += loss_phase.data.item()\n",
        "\n",
        "                val_corrects_tool += torch.sum(preds_tool == labels_tool.data.cpu())\n",
        "                val_corrects_phase += torch.sum(preds_phase == labels_phase.data)\n",
        "                # TODO\n",
        "\n",
        "                for i in range(len(preds_tool)):\n",
        "                    val_all_preds_tool.append(list(preds_tool.data.cpu()[i]))\n",
        "                for i in range(len(labels_tool)):\n",
        "                    val_all_labels_tool.append(list(labels_tool.data.cpu()[i]))\n",
        "                for i in range(len(preds_phase)):\n",
        "                    val_all_preds_phase.append(int(preds_phase.data.cpu()[i]))\n",
        "                for i in range(len(labels_phase)):\n",
        "                    val_all_labels_phase.append(int(labels_phase.data.cpu()[i]))\n",
        "\n",
        "\n",
        "                val_progress += 1\n",
        "                if val_progress*val_batch_size >= num_val_all:\n",
        "                    percent = 100.0\n",
        "                    print('Val progress: %s [%d/%d]' % (str(percent) + '%', num_val_all, num_val_all), end='\\n')\n",
        "                else:\n",
        "                    percent = round(val_progress*val_batch_size / num_val_all * 100, 2)\n",
        "                    print('Val progress: %s [%d/%d]' % (str(percent) + '%', val_progress*val_batch_size, num_val_all), end='\\r')\n",
        "\n",
        "        val_elapsed_time = time.time() - val_start_time\n",
        "        val_accuracy_tool = float(val_corrects_tool) / num_val_all / 7\n",
        "        val_average_loss_tool = val_loss_tool / num_val_all / 7\n",
        "        val_accuracy_phase = float(val_corrects_phase) / float(num_val_we_use)\n",
        "        val_average_loss_phase = val_loss_phase / num_val_we_use\n",
        "\n",
        "        val_all_preds_tool = np.array(val_all_preds_tool)\n",
        "        val_all_labels_tool = np.array(val_all_labels_tool)\n",
        "        val_precision_each_tool = metrics.precision_score(val_all_labels_tool,val_all_preds_tool, average=None)\n",
        "        val_recall_each_tool = metrics.recall_score(val_all_labels_tool,val_all_preds_tool, average=None)\n",
        "        val_precision_tool = metrics.precision_score(val_all_labels_tool,val_all_preds_tool, average=\"macro\")\n",
        "        val_recall_tool = metrics.recall_score(val_all_labels_tool,val_all_preds_tool, average=\"macro\")\n",
        "\n",
        "        val_recall_phase = metrics.recall_score(val_all_labels_phase,val_all_preds_phase, average='macro')\n",
        "        val_precision_phase = metrics.precision_score(val_all_labels_phase,val_all_preds_phase, average='macro')\n",
        "        val_jaccard_phase = metrics.jaccard_similarity_score(val_all_labels_phase,val_all_preds_phase)\n",
        "        val_precision_each_phase = metrics.precision_score(val_all_labels_phase,val_all_preds_phase, average=None)\n",
        "        val_recall_each_phase = metrics.recall_score(val_all_labels_phase,val_all_preds_phase, average=None)\n",
        "\n",
        "        writer.add_scalar('validation acc epoch tool',\n",
        "                          float(val_accuracy_tool),epoch)\n",
        "        writer.add_scalar('validation loss epoch tool',\n",
        "                          float(val_average_loss_tool),epoch)\n",
        "        writer.add_scalar('validation acc epoch phase',\n",
        "                          float(val_accuracy_phase),epoch)\n",
        "        writer.add_scalar('validation loss epoch phase',\n",
        "                          float(val_average_loss_phase),epoch)\n",
        "\n",
        "        print('epoch: {:4d}'\n",
        "              ' train in: {:2.0f}m{:2.0f}s'\n",
        "              ' train loss(phase/tool): {:4.4f}/{:4.4f}'\n",
        "              ' train accu(phase/tool): {:.4f}/{:.4f}'\n",
        "              ' valid in: {:2.0f}m{:2.0f}s'\n",
        "              ' valid loss(phase/tool): {:4.4f}/{:4.4f}'\n",
        "              ' valid accu(phase/tool): {:.4f}/{:.4f}'\n",
        "              .format(epoch,\n",
        "                      train_elapsed_time // 60,\n",
        "                      train_elapsed_time % 60,\n",
        "                      train_average_loss_phase,\n",
        "                      train_average_loss_tool,\n",
        "                      train_accuracy_phase,\n",
        "                      train_accuracy_tool,\n",
        "                      val_elapsed_time // 60,\n",
        "                      val_elapsed_time % 60,\n",
        "                      val_average_loss_phase,\n",
        "                      val_average_loss_tool,\n",
        "                      val_accuracy_phase,\n",
        "                      val_accuracy_tool))\n",
        "\n",
        "        print(\"val_precision_each_tool:\", val_precision_each_tool)\n",
        "        print(\"val_recall_each_tool:\", val_recall_each_tool)\n",
        "        print(\"val_precision_tool\", val_precision_tool)\n",
        "        print(\"val_recall_tool\", val_recall_tool)\n",
        "\n",
        "        print(\"val_precision_each_phase:\", val_precision_each_phase)\n",
        "        print(\"val_recall_each_phase:\", val_recall_each_phase)\n",
        "        print(\"val_precision_phase\", val_precision_phase)\n",
        "        print(\"val_recall_phase\", val_recall_phase)\n",
        "        print(\"val_jaccard_phase\", val_jaccard_phase)\n",
        "\n",
        "        if optimizer_choice == 0:\n",
        "            if sgd_adjust_lr == 0:\n",
        "                exp_lr_scheduler.step()\n",
        "            elif sgd_adjust_lr == 1:\n",
        "                exp_lr_scheduler.step(val_average_loss_tool+val_average_loss_phase)\n",
        "\n",
        "        if val_accuracy_phase > best_val_accuracy_phase:\n",
        "            best_val_accuracy_phase = val_accuracy_phase\n",
        "            best_val_accuracy_tool = val_accuracy_tool\n",
        "            correspond_train_acc_tool = train_accuracy_tool\n",
        "            correspond_train_acc_phase = train_accuracy_phase\n",
        "            best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "            best_epoch = epoch\n",
        "        elif val_accuracy_phase == best_val_accuracy_phase:\n",
        "            if val_accuracy_tool > best_val_accuracy_tool:\n",
        "                correspond_train_acc_tool = train_accuracy_tool\n",
        "                correspond_train_acc_phase = train_accuracy_phase\n",
        "                best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "                best_epoch = epoch\n",
        "            elif val_accuracy_tool == best_val_accuracy_tool:\n",
        "                if train_accuracy_phase > correspond_train_acc_phase:\n",
        "                    correspond_train_acc_phase = train_accuracy_phase\n",
        "                    correspond_train_acc_tool = train_accuracy_tool\n",
        "                    best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "                    best_epoch = epoch\n",
        "                elif train_accuracy_phase == correspond_train_acc_phase:\n",
        "                    if train_accuracy_tool > best_val_accuracy_tool:\n",
        "                        correspond_train_acc_tool = train_accuracy_tool\n",
        "                        best_model_wts = copy.deepcopy(model.module.state_dict())\n",
        "                        best_epoch = epoch\n",
        "\n",
        "        save_val_phase = int(\"{:4.0f}\".format(best_val_accuracy_phase * 10000))\n",
        "        save_val_tool = int(\"{:4.0f}\".format(best_val_accuracy_tool * 10000))\n",
        "        save_train_phase = int(\"{:4.0f}\".format(correspond_train_acc_phase * 10000))\n",
        "        save_train_tool = int(\"{:4.0f}\".format(correspond_train_acc_tool * 10000))\n",
        "        public_name = \"cnn_lstm_phase+tool\" \\\n",
        "                      + \"_epoch_\" + str(best_epoch) \\\n",
        "                      + \"_length_\" + str(sequence_length) \\\n",
        "                      + \"_opt_\" + str(optimizer_choice) \\\n",
        "                      + \"_mulopt_\" + str(multi_optim) \\\n",
        "                      + \"_flip_\" + str(use_flip) \\\n",
        "                      + \"_crop_\" + str(crop_type) \\\n",
        "                      + \"_batch_\" + str(train_batch_size) \\\n",
        "                      + \"_trainPhase_\" + str(save_train_phase) \\\n",
        "                      + \"_trainTool_\" + str(save_train_tool) \\\n",
        "                      + \"_valPhase_\" + str(save_val_phase) \\\n",
        "                      + \"_valTool_\" + str(save_val_tool)\n",
        "\n",
        "        #torch.save(best_model_wts, \"./best_model/\"+public_name+\".pth\")\n",
        "        print(\"best_epoch\",str(best_epoch))\n",
        "\n",
        "        # aus Code torch_version 0.4.0\n",
        "        #_______\n",
        "        model_name = public_name + \".pth\"\n",
        "        torch.save(best_model_wts, model_name)\n",
        "\n",
        "        record_name = public_name + \".npy\"\n",
        "        np.save(record_name, record_np)\n",
        "        #_______\n",
        "\n",
        "        torch.save(model.module.state_dict(), \"./temp_tool+phase/latest_model_\"+str(epoch)+\".pth\")\n",
        "        torch.save(best_model_wts, model_name)\n",
        "\n",
        "    print('best accuracy: {:.4f} cor train accu: {:.4f}'\n",
        "          .format(best_val_accuracy_tool, correspond_train_acc_tool))\n",
        "\n",
        "\n",
        "def main():\n",
        "    train_dataset, train_num_each, val_dataset, val_num_each = get_data('/content/drive/MyDrive/MA_LL/pytorch1.2.0/train_val_test_paths_labels.pkl')\n",
        "    train_model(train_dataset, train_num_each, val_dataset, val_num_each)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "print('Done')\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9b66ce11a84d442e9eaea0ddfc629795",
            "842bc5f7a92c42c9a06b51d2e84f0d76",
            "1433b350440a4233997257ccd857b308",
            "690d383641164ac49fb56727282bc2ad",
            "5f93d22f5c9d401cb78c8b6b8aee5130",
            "8fc029c3209647dd9c2ad9e4c957efc3",
            "2115855375454ff197e1e6ad81debd8e",
            "0f8e922c974445428e580408b3ff903a",
            "9b354fa8daf64a958940b1e22d743994",
            "9d63a31613c14f46b06d2df69423ae57",
            "10d7941bb01b40fda6edc25b5369261f"
          ]
        },
        "id": "FOjpHzX39YOH",
        "outputId": "c24c67d9-9773-458c-8c1e-204481b11b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of gpu   :      1\n",
            "sequence length :     10\n",
            "train batch size:    400\n",
            "valid batch size:    320\n",
            "optimizer choice:      0\n",
            "multiple optim  :      1\n",
            "num of epochs   :     25\n",
            "num of workers  :      8\n",
            "test crop type  :      1\n",
            "whether to flip :      1\n",
            "learning rate   : 0.0001\n",
            "momentum for sgd: 0.9000\n",
            "weight decay    : 0.0005\n",
            "dampening       : 0.0000\n",
            "use nesterov    :      0\n",
            "method for sgd  :      1\n",
            "step for sgd    :      5\n",
            "gamma for sgd   : 0.1000\n",
            "train_paths  :  27895\n",
            "train_labels :  27895\n",
            "valid_paths  :   5853\n",
            "valid_labels :   5853\n",
            "num of train dataset:  27895\n",
            "num train start idx :  25960\n",
            "last idx train start:  27886\n",
            "num of train we use :  25960\n",
            "num of all train use: 259600\n",
            "num of valid dataset:   5853\n",
            "num valid start idx :   5376\n",
            "last idx valid start:   5844\n",
            "num of valid we use :   5376\n",
            "num of all valid use:  53760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b66ce11a84d442e9eaea0ddfc629795"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bf22fb6fa896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-bf22fb6fa896>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_num_each\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_num_each\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/MA_LL/pytorch1.2.0/train_val_test_paths_labels.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_num_each\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_num_each\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-bf22fb6fa896>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_dataset, train_num_each, val_dataset, val_num_each)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./best_model_phase/lstm_epoch_10_length_10_opt_0_mulopt_1_flip_1_crop_1_batch_400_train_9940_val_7786.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./temp/lr5e-5/latest_model_tool_3.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './best_model_phase/lstm_epoch_10_length_10_opt_0_mulopt_1_flip_1_crop_1_batch_400_train_9940_val_7786.pth'"
          ]
        }
      ]
    }
  ]
}